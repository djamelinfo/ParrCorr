
import fr.inria.Indexing.{Configuration, RandomWalk}
import org.apache.commons.cli.{BasicParser, CommandLine, Options}
import org.apache.hadoop.fs.{FileSystem, Path}
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark._
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._
import org.apache.commons.math3.distribution.NormalDistribution
import org.apache.commons.math3.random.JDKRandomGenerator
import org.apache.spark.SparkConf
import org.apache.spark.api.java.function.Function
import org.apache.spark.api.java.function.PairFunction
import org.apache.spark.storage.StorageLevel
import org.apache.spark.streaming.Duration
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream
import org.apache.spark.streaming.api.java.JavaStreamingContext
import org.apache.spark.streaming.receiver.Receiver

import scala.util.control.Breaks._
import math._



object SlidingWindowiSAX {

  def main(args: Array[String]): Unit = {


    val nbrOfTimeSeries = 0;

    val conf = new SparkConf().setAppName("SlidingWindowiSAX")
    conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
      .set("spark.kryo.registrationRequired", "true")

    val sc  = new StreamingContext(conf, Seconds(1))

    val config = new Configuration()

    val lines = sc.receiverStream(new RandomWalk(nbrOfTimeSeries))




    //val s = lines.




    //-------------->>> u  use the first and not finished version  ->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>



  }






}